{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0da2c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_html_payload(payload):\n",
    "    \"\"\"\n",
    "    This function uses Beautiful Soup to read HTML data\n",
    "    and return the text.  If the payload is plain text, then\n",
    "    Beautiful Soup will return the original content\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(payload, 'html.parser')\n",
    "    return str(soup.get_text()).encode('utf-8').decode('utf-8')\n",
    "\n",
    "def parse_email(original_msg):\n",
    "    result = {}\n",
    "    #msg = parse_html_payload(original_msg)\n",
    "    msg = Parser(policy=default).parsestr(original_msg)\n",
    "    \n",
    "    msg = parse_html_payload(original_msg)\n",
    "    print(msg)\n",
    "    \n",
    "    body = msg.get_payload()\n",
    "    tuple_result = tuple([str(result.get(column, None)) for column in columns])\n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This creates a user-defined function which can be used in Spark\n",
    "parse_email_func = udf(lambda z: parse_email(z), email_struct)\n",
    "\n",
    "def parse_emails(input_df):\n",
    "    new_df = input_df.select(\n",
    "        'username', 'id', 'original_msg', parse_email_func('original_msg').alias('parsed_email')\n",
    "    )\n",
    "    for column in columns:\n",
    "        new_df = new_df.withColumn(column, new_df.parsed_email[column])\n",
    "    \n",
    "    new_df = new_df.drop('parsed_email')\n",
    "    return new_df\n",
    "        \n",
    "class ParseEmailsTransformer(Transformer):\n",
    "    def _transform(self, dataset):\n",
    "        \"\"\"\n",
    "        Transforms the input dataset.\n",
    "\n",
    "        :param dataset: input dataset, which is an instance of :py:class:`pyspark.sql.DataFrame`\n",
    "        :returns: transformed dataset\n",
    "        \"\"\"\n",
    "        return dataset.transform(parse_emails)\n",
    "\n",
    "## Use the custom ParseEmailsTransformer, Tokenizer, and CountVectorizer \n",
    "## to create a spark pipeline \n",
    "\n",
    "parse = ParseEmailsTransformer()\n",
    "tokenizer = Tokenizer(inputCol='original_msg', outputCol='words')\n",
    "vectorizer = CountVectorizer(inputCol=tokenizer.getOutputCol(), outputCol='features')\n",
    "#stages = parse\n",
    "stages = [parse, tokenizer, vectorizer]\n",
    "\n",
    "email_pipeline = Pipeline(stages=stages)\n",
    "\n",
    "model = email_pipeline.fit(df)\n",
    "result = model.transform(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
